# load the result grid and analyze different (practical) aspects of the
# training itself and the evolution of metrics

import sys 
import os
import matplotlib.pyplot as plt
import numpy as np
from helpers import *

# Add the root directory to the Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ray import tune
from scripts_to_run.train_cluster import train_loop

class Analyzer():
    def __init__(self, experiment_path, train_data_path):
        """Load the best model of a tuning session and analyze its latents
        
        Args:
            checkpoint_dir (str): path to the train session full ~/ray_results/TorchTrainer[...]
            train_data_path (str): path to the h5py file generated by the TaskDataModule
        """
        self.experiment_path = experiment_path
        self.best_model=None   # model.pt
        self.best_model_metadata = None   # format??
        self.result_grid = None
        (   self.train_input,
            self.train_target,
            self.train_init,
            self.val_input,
            self.val_target, 
            self.val_init
        ) = load_train_dataset(train_data_path)

        
    def load_result_grid(self):
        # load the result grid from the TorchTrainer experiment
        restored_tuner = tune.Tuner.restore(self.experiment_path, trainable=train_loop)
        self.result_grid = restored_tuner.result_grid()
    
    def load_best_model(self, metric='ptl/val_accuracy', mode='max'):
        """Load the best model/metadata from the best checkpoint in Result
            metric (str): The key for checkpoints to order on
            mode (str): One of [“min”, “max”]
            
            Call this function again to change the metrics for best model
        """
        if self.result_grid == None:
            self.load_result_grid()
        best_result = self.result_grid.get_best_result()
        best_checkpoint = best_result.get_best_checkpoint(metric=metric, mode=mode)
        self.metadata = best_checkpoint.get_metadata()
        with best_checkpoint.as_directory() as dir:
            self.model = dir['model.pt']

    def model(self, input=None, initial_states=None, val=True, 
              plot_trajs=False, plot_targets=False, plot_field=True, **kwargs):
        """Run inference, mimic the original torch interface.
        Return (readout, trajectories) for the given input and inits"""
        if self.best_model == None:
            self.load_best_model()
        # disable batch normalization, dropout, randomness
        self.best_model.eval()
        if input is None:
            input = self.val_input if val else self.train_input
        if initial_states is None:
            initial_states = self.val_init if val else self.train_init
        target = self.val_target if val else self.train_target
            
        # run inference
        readout, trajs = self.best_model(input, return_latents=True, initial_states=initial_states)
            
        # this will display a plot
        if plot_trajs:
            self.plot_trajectories(trajs, plot_field=plot_field, pca=kwargs.get('pca'), tsne=kwargs.get('tsne'))
            
        # this will also display a plot
        if plot_targets:
            self.plot_targets(input, target, readout)
            
        return readout, trajs

    def plot_trajectories(self, trajs, plot_field=True, pca=False, tsne=False):
        # trajs have shape (n_timesteps, n_trials, hidden_size = n_neurons)
        trials, timesteps, dimensions = trajs.shape
        colors = plt.cm.viridis(np.linspace(0, 1, trials))  # Generate different colors for each trial

        fig = plt.figure(figsize=(10, 6))

        if dimensions == 2:
            ax = fig.add_subplot(111)
            for trial in range(trials):
                ax.plot(trajs[trial, :, 0], trajs[trial, :, 1], color=colors[trial])#, label=f'Trial {trial+1}')
            ax.set_xlabel('latent 1')
            ax.set_ylabel('latent 2')
        elif dimensions == 3:
            ax = fig.add_subplot(111, projection='3d')
            for trial in range(trials):
                ax.plot(trajs[trial, :, 0], trajs[trial, :, 1], trajs[trial, :, 2], color=colors[trial])#, label=f'Trial {trial+1}')
            ax.set_xlabel('latent 1')
            ax.set_ylabel('latent 2')
            ax.set_zlabel('latent 3')
        else:
            raise ValueError("FOR NOW Dimensions must be 2 or 3 for plotting.")
        
        # TODO: implement pca/tsne

        plt.show()
        
    def get_field_data(self, domain=[[-1,1],[-1,1]]):
        """Return the values for the vectors in the vecgtor field
        created by some model
        domain: list of the axis limits for every dimension
        """
        
        
        
                
    def plot_targets(self, inputs, targets, readout, phase_index=None):
        
        # TODO: generalize, this is labeled only for the CDM task
        
        inputs = inputs.squeeze().numpy() 
        targets = targets.squeeze().numpy()
        
        # plot the inputs and targets
        fig, ax = plt.subplots(1, 2, figsize=(10, 5))
        ax[0].plot(inputs, label=['Channel 0', 'Channel 1', 'Context 0', 'Context 1'])
        ax[0].set_xlim(0, len(inputs))
        ax[0].legend()
        ax[1].plot(targets, color='k', label='targets')
        ax[1].plot(readout, color='r', label='readout')  # BUG: maybe this sould NOT be the readout??
        
        # plot vertical dotted lines at x values of phase_index
        if phase_index:
            for key, val in phase_index.items():
                ax[0].axvline(x=val, color='k', linestyle='--')
                ax[1].axvline(x=val, color='k', linestyle='--')
            
        # add labels
        ax[0].set_xlabel("Binned timesteps (bin_size = {})".format(self.bin_size))
        ax[0].set_ylabel("Input amplitude")
        ax[1].set_xlabel("Binned timesteps (bin_size = {})".format(self.bin_size))
        ax[1].set_ylabel("Target vs Predictions")
        
        # return the image
        return fig
