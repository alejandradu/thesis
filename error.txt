
CondaError: Run 'conda init' before 'conda activate'

2025-02-07 02:21:13,450	INFO worker.py:1841 -- Started a local Ray instance.
2025-02-07 02:21:18,143	INFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.
2025-02-07 02:21:18,176	INFO data_parallel_trainer.py:340 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.
[36m(TorchTrainer pid=1905074)[0m GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.
[36m(RayTrainWorker pid=1905300)[0m Setting up process group for: env:// [rank=0, world_size=8]
[36m(TorchTrainer pid=1905074)[0m Started distributed worker processes: 
[36m(TorchTrainer pid=1905074)[0m - (node_id=aadb895be29ccfcd90af548e9e222a8d5edd767fafe19898b7c22961, ip=172.17.6.67, pid=1905300) world_rank=0, local_rank=0, node_rank=0
[36m(TorchTrainer pid=1905074)[0m - (node_id=aadb895be29ccfcd90af548e9e222a8d5edd767fafe19898b7c22961, ip=172.17.6.67, pid=1905302) world_rank=1, local_rank=1, node_rank=0
[36m(TorchTrainer pid=1905074)[0m - (node_id=aadb895be29ccfcd90af548e9e222a8d5edd767fafe19898b7c22961, ip=172.17.6.67, pid=1905309) world_rank=2, local_rank=2, node_rank=0
[36m(TorchTrainer pid=1905074)[0m - (node_id=aadb895be29ccfcd90af548e9e222a8d5edd767fafe19898b7c22961, ip=172.17.6.67, pid=1905301) world_rank=3, local_rank=3, node_rank=0
[36m(TorchTrainer pid=1905074)[0m - (node_id=aadb895be29ccfcd90af548e9e222a8d5edd767fafe19898b7c22961, ip=172.17.6.67, pid=1905306) world_rank=4, local_rank=4, node_rank=0
[36m(TorchTrainer pid=1905074)[0m - (node_id=aadb895be29ccfcd90af548e9e222a8d5edd767fafe19898b7c22961, ip=172.17.6.67, pid=1905308) world_rank=5, local_rank=5, node_rank=0
[36m(TorchTrainer pid=1905074)[0m - (node_id=aadb895be29ccfcd90af548e9e222a8d5edd767fafe19898b7c22961, ip=172.17.6.67, pid=1905303) world_rank=6, local_rank=6, node_rank=0
[36m(TorchTrainer pid=1905074)[0m - (node_id=aadb895be29ccfcd90af548e9e222a8d5edd767fafe19898b7c22961, ip=172.17.6.67, pid=1905310) world_rank=7, local_rank=7, node_rank=0
[36m(RayTrainWorker pid=1905300)[0m GPU available: False, used: False
[36m(RayTrainWorker pid=1905300)[0m TPU available: False, using: 0 TPU cores
[36m(RayTrainWorker pid=1905300)[0m HPU available: False, using: 0 HPUs
[36m(RayTrainWorker pid=1905300)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.
[36m(RayTrainWorker pid=1905300)[0m 
[36m(RayTrainWorker pid=1905300)[0m   | Name  | Type  | Params | Mode 
[36m(RayTrainWorker pid=1905300)[0m ----------------------------------------
[36m(RayTrainWorker pid=1905300)[0m 0 | model | frRNN | 175    | train
[36m(RayTrainWorker pid=1905300)[0m ----------------------------------------
[36m(RayTrainWorker pid=1905300)[0m 105       Trainable params
[36m(RayTrainWorker pid=1905300)[0m 70        Non-trainable params
[36m(RayTrainWorker pid=1905300)[0m 175       Total params
[36m(RayTrainWorker pid=1905300)[0m 0.001     Total estimated model params size (MB)
[36m(RayTrainWorker pid=1905300)[0m 1         Modules in train mode
[36m(RayTrainWorker pid=1905300)[0m 0         Modules in eval mode
[36m(RayTrainWorker pid=1905300)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(RayTrainWorker pid=1905300)[0m   warnings.warn(
[36m(RayTrainWorker pid=1905300)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000000)
2025-02-07 02:21:41,452	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(RayTrainWorker pid=1905310)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(RayTrainWorker pid=1905310)[0m   warnings.warn([32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000002)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000004)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000006)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000008)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000010)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000012)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000014)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000016)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000018)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000020)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000022)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000024)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000026)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000028)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000030)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905302)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000032)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000034)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000036)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000038)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000040)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000042)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000044)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000046)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=1905300)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000048)[32m [repeated 16x across cluster][0m
2025-02-07 02:24:04,278	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12' in 0.0039s.
[36m(RayTrainWorker pid=1905310)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-02-07_02-21-12/TorchTrainer_1f7a5_00000_0_lr=0.0010,noise_std=0.1000,weight_decay=0.0010_2025-02-07_02-21-18/checkpoint_000049)[32m [repeated 15x across cluster][0m
