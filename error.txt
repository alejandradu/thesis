2025-03-11 16:53:17,289	INFO worker.py:1841 -- Started a local Ray instance.
2025-03-11 16:53:20,594	INFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.
2025-03-11 16:53:20,647	INFO data_parallel_trainer.py:340 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.
2025-03-11 16:53:20,650	INFO data_parallel_trainer.py:340 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.
2025-03-11 16:53:20,652	INFO data_parallel_trainer.py:340 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.
2025-03-11 16:53:20,654	INFO data_parallel_trainer.py:340 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.
2025-03-11 16:53:20,656	INFO data_parallel_trainer.py:340 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.
2025-03-11 16:53:20,658	INFO data_parallel_trainer.py:340 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.
2025-03-11 16:53:20,660	INFO data_parallel_trainer.py:340 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.
2025-03-11 16:53:20,662	INFO data_parallel_trainer.py:340 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.
[36m(TorchTrainer pid=728293)[0m GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.
[36m(RayTrainWorker pid=729419)[0m Setting up process group for: env:// [rank=0, world_size=8]
[36m(TorchTrainer pid=728290)[0m GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(TorchTrainer pid=728293)[0m Started distributed worker processes: 
[36m(TorchTrainer pid=728293)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729419) world_rank=0, local_rank=0, node_rank=0
[36m(TorchTrainer pid=728293)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729406) world_rank=1, local_rank=1, node_rank=0
[36m(TorchTrainer pid=728293)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729428) world_rank=2, local_rank=2, node_rank=0
[36m(TorchTrainer pid=728293)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729423) world_rank=3, local_rank=3, node_rank=0
[36m(TorchTrainer pid=728293)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729439) world_rank=4, local_rank=4, node_rank=0
[36m(TorchTrainer pid=728293)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729466) world_rank=5, local_rank=5, node_rank=0
[36m(TorchTrainer pid=728293)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729438) world_rank=6, local_rank=6, node_rank=0
[36m(TorchTrainer pid=728293)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729441) world_rank=7, local_rank=7, node_rank=0
[36m(RayTrainWorker pid=729475)[0m Setting up process group for: env:// [rank=0, world_size=8][32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=729419)[0m GPU available: False, used: False
[36m(RayTrainWorker pid=729419)[0m TPU available: False, using: 0 TPU cores
[36m(RayTrainWorker pid=729419)[0m HPU available: False, using: 0 HPUs
[36m(RayTrainWorker pid=729419)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.
[36m(TorchTrainer pid=728294)[0m Started distributed worker processes: 
[36m(TorchTrainer pid=728294)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729460) world_rank=0, local_rank=0, node_rank=0
[36m(TorchTrainer pid=728294)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729462) world_rank=1, local_rank=1, node_rank=0
[36m(TorchTrainer pid=728294)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729461) world_rank=2, local_rank=2, node_rank=0
[36m(TorchTrainer pid=728294)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729468) world_rank=3, local_rank=3, node_rank=0
[36m(TorchTrainer pid=728294)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729469) world_rank=4, local_rank=4, node_rank=0
[36m(TorchTrainer pid=728294)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729473) world_rank=5, local_rank=5, node_rank=0
[36m(TorchTrainer pid=728294)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729459) world_rank=6, local_rank=6, node_rank=0
[36m(TorchTrainer pid=728294)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729453) world_rank=7, local_rank=7, node_rank=0
[36m(RayTrainWorker pid=729419)[0m 
[36m(RayTrainWorker pid=729419)[0m   | Name  | Type | Params | Mode 
[36m(RayTrainWorker pid=729419)[0m ---------------------------------------
[36m(RayTrainWorker pid=729419)[0m 0 | model | nODE | 12.9 K | train
[36m(RayTrainWorker pid=729419)[0m ---------------------------------------
[36m(RayTrainWorker pid=729419)[0m 12.9 K    Trainable params
[36m(RayTrainWorker pid=729419)[0m 0         Non-trainable params
[36m(RayTrainWorker pid=729419)[0m 12.9 K    Total params
[36m(RayTrainWorker pid=729419)[0m 0.052     Total estimated model params size (MB)
[36m(RayTrainWorker pid=729419)[0m 13        Modules in train mode
[36m(RayTrainWorker pid=729419)[0m 0         Modules in eval mode
[36m(RayTrainWorker pid=729402)[0m Setting up process group for: env:// [rank=0, world_size=8][32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m GPU available: False, used: False
[36m(RayTrainWorker pid=729402)[0m TPU available: False, using: 0 TPU cores
[36m(RayTrainWorker pid=729402)[0m HPU available: False, using: 0 HPUs
[36m(RayTrainWorker pid=729402)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.
[36m(TorchTrainer pid=728291)[0m Started distributed worker processes: [32m [repeated 4x across cluster][0m
[36m(TorchTrainer pid=728291)[0m - (node_id=4ed6bc3a598b56cfc83f7957f105e9289262661fad4f4a105763f80c, ip=172.17.6.108, pid=729411) world_rank=7, local_rank=7, node_rank=0[32m [repeated 32x across cluster][0m
[36m(RayTrainWorker pid=729475)[0m GPU available: False, used: False
[36m(RayTrainWorker pid=729475)[0m TPU available: False, using: 0 TPU cores
[36m(RayTrainWorker pid=729475)[0m HPU available: False, using: 0 HPUs
[36m(RayTrainWorker pid=729475)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.
[36m(RayTrainWorker pid=729402)[0m 
[36m(RayTrainWorker pid=729402)[0m   | Name  | Type | Params | Mode 
[36m(RayTrainWorker pid=729402)[0m ---------------------------------------
[36m(RayTrainWorker pid=729402)[0m 0 | model | nODE | 456    | train
[36m(RayTrainWorker pid=729402)[0m ---------------------------------------
[36m(RayTrainWorker pid=729402)[0m 456       Trainable params
[36m(RayTrainWorker pid=729402)[0m 0         Non-trainable params
[36m(RayTrainWorker pid=729402)[0m 456       Total params
[36m(RayTrainWorker pid=729402)[0m 0.002     Total estimated model params size (MB)
[36m(RayTrainWorker pid=729402)[0m 7         Modules in train mode
[36m(RayTrainWorker pid=729402)[0m 0         Modules in eval mode
[36m(RayTrainWorker pid=729475)[0m 
[36m(RayTrainWorker pid=729475)[0m 0 | model | nODE | 12.9 K | train
[36m(RayTrainWorker pid=729475)[0m 12.9 K    Trainable params
[36m(RayTrainWorker pid=729475)[0m 12.9 K    Total params
[36m(RayTrainWorker pid=729417)[0m 
[36m(RayTrainWorker pid=729460)[0m 
[36m(RayTrainWorker pid=729455)[0m 
[36m(RayTrainWorker pid=729419)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
[36m(RayTrainWorker pid=729455)[0m GPU available: False, used: False[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m TPU available: False, using: 0 TPU cores[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m HPU available: False, using: 0 HPUs[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m   | Name  | Type | Params | Mode [32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m ---------------------------------------[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m 0 | model | nODE | 456    | train[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m 456       Trainable params[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m 0         Non-trainable params[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m 456       Total params[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m 0.002     Total estimated model params size (MB)[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m 7         Modules in train mode[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m 0         Modules in eval mode[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
[36m(RayTrainWorker pid=729417)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
[36m(RayTrainWorker pid=729419)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000000)
[36m(RayTrainWorker pid=729455)[0m /home/ad2002/.conda/envs/neuralnets/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000000)[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=729419)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000001)[32m [repeated 40x across cluster][0m
[36m(RayTrainWorker pid=729460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00005_5_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000001)[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=729419)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000002)[32m [repeated 40x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000002)[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=729423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000003)[32m [repeated 40x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000003)[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=729406)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000004)[32m [repeated 40x across cluster][0m
[36m(RayTrainWorker pid=729417)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00003_3_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000004)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000005)[32m [repeated 32x across cluster][0m
[36m(RayTrainWorker pid=729475)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00002_2_lr=0.0010,num_layers=5,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000005)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=729419)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000006)[32m [repeated 32x across cluster][0m
[36m(RayTrainWorker pid=729417)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00003_3_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000006)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000007)[32m [repeated 32x across cluster][0m
[36m(RayTrainWorker pid=729460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00005_5_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000007)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=729413)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000008)[32m [repeated 32x across cluster][0m
[36m(RayTrainWorker pid=729460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00005_5_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000008)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000009)[32m [repeated 32x across cluster][0m
[36m(RayTrainWorker pid=729460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00005_5_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000009)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=729419)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000010)[32m [repeated 40x across cluster][0m
[36m(RayTrainWorker pid=729455)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00001_1_lr=0.0001,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000010)[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000011)[32m [repeated 32x across cluster][0m
[36m(RayTrainWorker pid=729460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00005_5_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000011)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=729475)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00002_2_lr=0.0010,num_layers=5,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000011)[32m [repeated 24x across cluster][0m
[36m(RayTrainWorker pid=729417)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00003_3_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000012)[32m [repeated 24x across cluster][0m
[36m(RayTrainWorker pid=729415)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000013)[32m [repeated 24x across cluster][0m
[36m(RayTrainWorker pid=729410)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00001_1_lr=0.0001,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000013)[32m [repeated 24x across cluster][0m
[36m(RayTrainWorker pid=729406)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000014)[32m [repeated 24x across cluster][0m
[36m(RayTrainWorker pid=729408)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00001_1_lr=0.0001,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000014)[32m [repeated 24x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000015)[32m [repeated 24x across cluster][0m
[36m(RayTrainWorker pid=729460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00005_5_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000015)[32m [repeated 32x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000016)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=729419)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000016)[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=729475)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00002_2_lr=0.0010,num_layers=5,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000015)[32m [repeated 32x across cluster][0m
[36m(RayTrainWorker pid=729419)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000017)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=729460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00005_5_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000017)[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=729406)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000018)[32m [repeated 40x across cluster][0m
[36m(RayTrainWorker pid=729460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00005_5_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000018)[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=729419)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000019)[32m [repeated 40x across cluster][0m
[36m(RayTrainWorker pid=729460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00005_5_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000019)[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000020)[32m [repeated 16x across cluster][0m
[36m(RayTrainWorker pid=729419)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00000_0_lr=0.0001,num_layers=5,weight_decay=0.0000_2025-03-11_16-53-20/checkpoint_000020)[32m [repeated 24x across cluster][0m
[36m(RayTrainWorker pid=729460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00005_5_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000020)[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=729402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/scratch/gpfs/ad2002/task_training/ray_results/TorchTrainer_2025-03-11_16-53-15/TorchTrainer_dd8a6_00004_4_lr=0.0010,num_layers=2,weight_decay=0.0010_2025-03-11_16-53-20/checkpoint_000021)[32m [repeated 8x across cluster][0m
